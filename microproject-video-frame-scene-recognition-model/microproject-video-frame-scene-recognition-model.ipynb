{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{},"source":["<h1 style=\"text-align: center\">\n","<div style=\"color: #DD3403; font-size: 60%\">Data Science DISCOVERY MicroProject</div>\n","<span style=\"\">MicroProject: Building a Scene Recognition Model form Video Frames</span>\n","<div style=\"font-size: 60%;\"><a href=\"https://discovery.cs.illinois.edu/microproject/video-frame-scene-recognition-model/\">https://discovery.cs.illinois.edu/microproject/video-frame-scene-recognition-model/</a></div>\n","</h1>\n","\n","<hr style=\"color: #DD3403;\">"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Data Source: Frames of a Video\n","\n","Visual images are an important part of all media and Data Scientists are often using images as data sources.  In this MicroProject, you will create a simple model to detect the amount of time spent in two different \"scenes\" we used when creating office-hour style videos for Data Science DISCOVERY.  To do this, you will learn how to import an entire folder of images, preform image analysis, and create your own model without using a pre-build library.  Let's nerd out! :)\n","\n","> *This MicroProject was inspired by a podcast that we recently recorded with the team from the Center for Innovation in Teaching and Learning who helped produce our video.  To learn the background and hear from Karle and Wade about the journey of creating DISCOVERY, go over and listen to our episode on the \"Teach Talk Listen Learn Podcast\" where talk with TTLL host Bob Dignan and our CITL video producer Eric Schumacher: https://citl.illinois.edu/citl-101/teaching-learning/teach-talk-listen-learn*\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Loading Video Frames\n","\n","We have provided you with one frame every second from our video [*\"Outliers Impact on Correlation (m6-02b)\"*](https://www.youtube.com/watch?v=bd6hQ2UcIJc) that is used as part of our [DISCOVERY lecture covering Correlation](https://discovery.cs.illinois.edu/learn/Towards-Machine-Learning/Correlation/).  Each of these frames are in the `frames` sub-folder.\n","\n","The `skimage` library is commonly used to load image data into Python.  Specifically:\n","\n","- The full function name we will be using is `skimage.io.imread(filename)`.  This function will read a filename and return the pixel color for every pixel in the image.\n","\n","- To use the `imread` function, you will need to either do one of the following:\n","\n","    1. Import the entire `skimage` library by using the import line: `import skimage`.  After importing all of `skimage`, you will call the function using it's fully qualified name: `skimage.io.imread(filename)`.\n","    \n","    **ALTERATIVELY**\n","    \n","    2. Import only the `imread` function by using the more specific import line: `from sklearn.io import imread`.  After importing only `imread`, you will call the function directly: `imread(filename)`\n","\n","    *(People's preference differs on how they prefer to import and use libraries.  Both techniques work! :))*\n","\n","### Read Pixel Data for `frames/frame_0001.jpg`\n","\n","As noted earlier, we have provided a `frames` directory with all of the frames.\n","\n","In the following cell, store the pixel color data from the file named `frames/frame_0001.jpg` image in the variable `pixels` by using the `imread` function:\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"data":{"text/plain":["array([[[ 91,  83,  80],\n","        [ 91,  83,  80],\n","        [ 91,  83,  80],\n","        ...,\n","        [ 75,  72,  79],\n","        [ 80,  78,  83],\n","        [ 83,  81,  86]],\n","\n","       [[ 91,  83,  80],\n","        [ 91,  83,  80],\n","        [ 91,  83,  80],\n","        ...,\n","        [ 73,  70,  77],\n","        [ 79,  77,  82],\n","        [ 83,  81,  86]],\n","\n","       [[ 91,  83,  80],\n","        [ 91,  83,  80],\n","        [ 91,  83,  80],\n","        ...,\n","        [ 69,  66,  73],\n","        [ 77,  75,  80],\n","        [ 83,  81,  86]],\n","\n","       ...,\n","\n","       [[174, 142, 121],\n","        [174, 142, 121],\n","        [174, 142, 121],\n","        ...,\n","        [163, 131, 110],\n","        [163, 131, 110],\n","        [163, 131, 110]],\n","\n","       [[174, 142, 121],\n","        [174, 142, 121],\n","        [175, 143, 122],\n","        ...,\n","        [162, 131, 110],\n","        [162, 131, 110],\n","        [162, 131, 110]],\n","\n","       [[173, 141, 120],\n","        [174, 142, 121],\n","        [175, 143, 122],\n","        ...,\n","        [162, 131, 110],\n","        [162, 131, 110],\n","        [162, 131, 110]]], dtype=uint8)"]},"execution_count":1,"metadata":{},"output_type":"execute_result"}],"source":["from skimage.io import imread \n","pixels = imread(\"frames/frame_0001.jpg\")\n","pixels"]},{"cell_type":"markdown","metadata":{},"source":["### ðŸ”¬ Checkpoint Tests ðŸ”¬"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["ðŸŽ‰ All Tests Passed! ðŸŽ‰\n"]}],"source":["## == CHECKPOINT TESTS ==\n","# - This read-only cell contains a \"checkpoint\" for this section of the MicroProejct and verifies you are on the right track.\n","# - If this cell results in a celebration message, you PASSED all test cases!\n","# - If this cell results in any errors, check you previous cells, make changes, and RE-RUN your code and then this cell.\n","tada = \"\\N{PARTY POPPER}\"\n","\n","assert(\"pixels\" in vars())\n","assert(pixels.shape == (360, 640, 3))\n","assert(pixels[0][0][0] == 91)\n","\n","print(f\"{tada} All Tests Passed! {tada}\")"]},{"cell_type":"markdown","metadata":{},"source":["<hr style=\"color: #DD3403;\">"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Part 1: Storing Average Pixel Color\n","\n","The **shape** of your data is the `rows` by `columns` by `color values` as 3-dimensional list.  Here's a formatted view of your `pixels` data:\n","\n","```\n","[\n","  [ [91, 83, 80], [91, 83, 80], [91, 83, 80] ], ... ],   # Row #1\n","  [ [91, 83, 80], [91, 83, 80], [91, 83, 80] ], ... ],   # Row #2\n","  ...                                                    # ...\n","]\n","```\n","\n","The current shape of `pixels` is 360 rows by 640 columns by 3 colors (`360` x `640` x `3`).  Each of the three colors represent the three color channels on a screen: red, green, and blue.\n","\n","Using `pixel.mean()`, we find the average color grouping **ALL** the color channels (combining blues and reds and greens together).  Try it out:\n"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"data":{"text/plain":["72.18011863425926"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["pixels.mean()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["This value is not very useful.  It is the average of red, green, and blue all lumped together -- it would be far more useful to find the average **red**, average **green**, and average **blue** independently.\n","\n","To do that, we first need to \"flatten\" the list so that we have a list of only color data instead of a list of rows, columns, and then color data.  That means we want our list to look like the following:\n","\n","```\n","[\n","  [ 91, 83, 80 ],    # Pixel #1 color data\n","  [ 91, 83, 80 ],    # Pixel #2 color data\n","  [ 91, 83, 80 ],    # Pixel #3 color data\n","  ...\n","]\n","```\n","\n","### Using `pixels.reshape()`\n","\n","Now that we have the desired shape of the list, the `reshape` function can do the hard work!  We know we want the final shape to be `?`x `3`.  As long as you only have one unknown dimensions, Python allows you to provide a `-1` and it will place all of the data there.\n","\n","That means `pixels.reshape(-1, 3)` will reshape our list to be a single long list of color data.  Let's try out that transformation:"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"data":{"text/plain":["array([[ 91,  83,  80],\n","       [ 91,  83,  80],\n","       [ 91,  83,  80],\n","       ...,\n","       [162, 131, 110],\n","       [162, 131, 110],\n","       [162, 131, 110]], dtype=uint8)"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["pixels = pixels.reshape(-1, 3)\n","pixels"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Finally, we want the average value of each element of the list.  To do this, `pixels.mean(axis=0)` finds the average color of each element of our newly formatted list of pixels:"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"data":{"text/plain":["array([88.65917535, 67.45620226, 60.4249783 ])"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["pixels.mean(axis=0)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Puzzle 1.1: Finding the Average Color of One Image\n","\n","Given the output you learned above, write the Python code to store `pixel`'s average red value in `r`, average green value in `g`, and average blue value in `b`:"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["r = pixels.mean(axis=0)[0]\n","g = pixels.mean(axis=0)[1]\n","b = pixels.mean(axis=0)[2]"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["ðŸŽ‰ All Tests Passed! ðŸŽ‰\n"]}],"source":["## == CHECKPOINT TESTS ==\n","# - This read-only cell contains a \"checkpoint\" for this section of the MicroProejct and verifies you are on the right track.\n","# - If this cell results in a celebration message, you PASSED all test cases!\n","# - If this cell results in any errors, check you previous cells, make changes, and RE-RUN your code and then this cell.\n","tada = \"\\N{PARTY POPPER}\"\n","\n","import math\n","assert(\"r\" in vars())\n","assert(\"g\" in vars())\n","assert(\"b\" in vars())\n","assert(math.isclose(r, 88.65917534722222))\n","assert(math.isclose(g, 67.45620225694445))\n","assert(math.isclose(b, 60.42497829861111))\n","\n","print(f\"{tada} All Tests Passed! {tada}\")"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Puzzle 1.2: Finding the Average Color of All Images\n","\n","The following code loops through every file in the `frames` directory -- this will include `frame_0001.jpg` (like you analyzed already) and also `frame_0002.jpg`, `frame_0003.jpg`, and all 300+ frames!\n","\n","Create a DataFrame where each row is one frame with the following four columns:\n","- `frame`, the filename of the frame\n","- `r`, the average red color of the frame\n","- `g`, the average green color of the frame\n","- `b`, the average blue color of the frame\n","\n","The structure of the code should be nearly **identical to writing a simulation**.  For \"Step 3\" when you would normally simulate a random variable for the real-world event, you should instead use the real world data.  This real world data will be filename `frame`, and the `r`, `g`, and `b` values should be the average color of that frame.\n","\n","- See: https://discovery.cs.illinois.edu/learn/Simulation-and-Distributions/Simple-Simulations-in-Python/"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["import glob\n","import os\n","import pandas as pd\n","\n","data = []\n","for frame in glob.glob(os.path.join(\"frames\", \"*.jpg\")): \n","  # `frame`` contains the filename of the frame (ex: \"frames/frame_0001.jpg\").  Use it for `imread` to read the frame image data.\n","  pixels = imread(frame)\n","  pixels = pixels.reshape(-1, 3)\n","  r = pixels.mean(axis=0)[0]\n","  g = pixels.mean(axis=0)[1]\n","  b = pixels.mean(axis=0)[2]\n","  d = {\"r\" : r, \"g\" : g, \"b\" : b, \"frame\" : frame}\n","  data.append(d)\n","  \n","\n","df = pd.DataFrame(data)"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>r</th>\n","      <th>g</th>\n","      <th>b</th>\n","      <th>frame</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>88.659175</td>\n","      <td>67.456202</td>\n","      <td>60.424978</td>\n","      <td>frames\\frame_0001.jpg</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>88.697865</td>\n","      <td>67.453529</td>\n","      <td>60.475660</td>\n","      <td>frames\\frame_0002.jpg</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>88.028351</td>\n","      <td>66.913845</td>\n","      <td>60.064592</td>\n","      <td>frames\\frame_0003.jpg</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>88.825629</td>\n","      <td>67.340347</td>\n","      <td>60.491645</td>\n","      <td>frames\\frame_0004.jpg</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>88.211714</td>\n","      <td>66.979661</td>\n","      <td>59.983173</td>\n","      <td>frames\\frame_0005.jpg</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>325</th>\n","      <td>7.470391</td>\n","      <td>7.473355</td>\n","      <td>7.479188</td>\n","      <td>frames\\frame_0326.jpg</td>\n","    </tr>\n","    <tr>\n","      <th>326</th>\n","      <td>7.469779</td>\n","      <td>7.472743</td>\n","      <td>7.478576</td>\n","      <td>frames\\frame_0327.jpg</td>\n","    </tr>\n","    <tr>\n","      <th>327</th>\n","      <td>7.480234</td>\n","      <td>7.481519</td>\n","      <td>7.487826</td>\n","      <td>frames\\frame_0328.jpg</td>\n","    </tr>\n","    <tr>\n","      <th>328</th>\n","      <td>7.480004</td>\n","      <td>7.481289</td>\n","      <td>7.487595</td>\n","      <td>frames\\frame_0329.jpg</td>\n","    </tr>\n","    <tr>\n","      <th>329</th>\n","      <td>4.657478</td>\n","      <td>4.658776</td>\n","      <td>4.665082</td>\n","      <td>frames\\frame_0330.jpg</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>330 rows Ã— 4 columns</p>\n","</div>"],"text/plain":["             r          g          b                  frame\n","0    88.659175  67.456202  60.424978  frames\\frame_0001.jpg\n","1    88.697865  67.453529  60.475660  frames\\frame_0002.jpg\n","2    88.028351  66.913845  60.064592  frames\\frame_0003.jpg\n","3    88.825629  67.340347  60.491645  frames\\frame_0004.jpg\n","4    88.211714  66.979661  59.983173  frames\\frame_0005.jpg\n","..         ...        ...        ...                    ...\n","325   7.470391   7.473355   7.479188  frames\\frame_0326.jpg\n","326   7.469779   7.472743   7.478576  frames\\frame_0327.jpg\n","327   7.480234   7.481519   7.487826  frames\\frame_0328.jpg\n","328   7.480004   7.481289   7.487595  frames\\frame_0329.jpg\n","329   4.657478   4.658776   4.665082  frames\\frame_0330.jpg\n","\n","[330 rows x 4 columns]"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["df"]},{"cell_type":"markdown","metadata":{},"source":["### ðŸ”¬ Checkpoint Tests ðŸ”¬"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["ðŸŽ‰ All Tests Passed! ðŸŽ‰\n"]}],"source":["## == CHECKPOINT TESTS ==\n","# - This read-only cell contains a \"checkpoint\" for this section of the MicroProejct and verifies you are on the right track.\n","# - If this cell results in a celebration message, you PASSED all test cases!\n","# - If this cell results in any errors, check you previous cells, make changes, and RE-RUN your code and then this cell.\n","tada = \"\\N{PARTY POPPER}\"\n","\n","import math\n","assert(\"df\" in vars())\n","assert(len(df) == 330)\n","assert(\"r\" in df)\n","assert(\"g\" in df)\n","assert(\"b\" in df)\n","assert(\"frame\" in df)\n","assert( abs( df[ df.frame.str.endswith(\"_0001.jpg\") ][\"r\"].sum() - 88 ) < 1 )\n","\n","print(f\"{tada} All Tests Passed! {tada}\")"]},{"cell_type":"markdown","metadata":{},"source":["<hr style=\"color: #DD3403;\">"]},{"cell_type":"markdown","metadata":{},"source":["## Part 2: Create a Simple Classifier\n","\n","In the DISCOVERY lecture videos, there are two primary \"scenes\" in the video:\n","\n","1. **\"Office Hours Studio Scene\"**, where Karle and Wade are talking to each other and the audience,\n","\n","2. **\"Notebook Scene\"**, where the notebook is displayed\n","\n","View the `frames` folder on your computer and find **at least three more frames** that are in the \"office hours studio scene\" and **at least three more frames** that are in the \"notebook scene\".  Add the frames you found to the list below:"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["# List of at least four office hour frames by the filename's frame number:\n","office_hour_frames = [1, 2, 3, 4, 5, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]\n","\n","# List of at least four notebook frames by the filename's frame number:\n","notebook_frames = [30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54]"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Observing the Average Colors of Your Frames\n","\n","The following code uses your sample frames to display the average color values for your selected frames.  This information about the average color of the two different type of frames will be useful for you to build the classifier in the next section.\n","\n","You may want to add more frames into your list above to get more data to help build your classifier.  Run the following code to see the average color values:"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["== Office Hour Frames ==\n","             r          g          b                  frame\n","0    88.659175  67.456202  60.424978  frames\\frame_0001.jpg\n","1    88.697865  67.453529  60.475660  frames\\frame_0002.jpg\n","2    88.028351  66.913845  60.064592  frames\\frame_0003.jpg\n","3    88.825629  67.340347  60.491645  frames\\frame_0004.jpg\n","4    88.211714  66.979661  59.983173  frames\\frame_0005.jpg\n","8    88.963446  66.552773  59.458294  frames\\frame_0009.jpg\n","9   108.020807  53.174227  44.903989  frames\\frame_0010.jpg\n","10  106.510043  53.178854  44.992795  frames\\frame_0011.jpg\n","11  106.565577  53.084271  45.153090  frames\\frame_0012.jpg\n","12  106.535226  52.983685  45.031502  frames\\frame_0013.jpg\n","13  107.287148  53.664076  45.780673  frames\\frame_0014.jpg\n","14  106.867882  53.494240  45.379852  frames\\frame_0015.jpg\n","15  106.216827  52.878997  44.989566  frames\\frame_0016.jpg\n","16  108.083845  53.682270  45.474601  frames\\frame_0017.jpg\n","17   90.887626  65.819722  58.584336  frames\\frame_0018.jpg\n","18   88.007270  67.002426  59.679549  frames\\frame_0019.jpg\n","19   87.650078  66.533685  59.362396  frames\\frame_0020.jpg\n","20   87.667374  66.617891  59.294557  frames\\frame_0021.jpg\n","21   87.795200  66.529692  59.443464  frames\\frame_0022.jpg\n","22   87.882791  66.839562  59.662582  frames\\frame_0023.jpg\n","23   88.317817  66.974431  60.013902  frames\\frame_0024.jpg\n","24   87.673837  66.656454  59.014805  frames\\frame_0025.jpg\n","25   88.111723  67.775538  59.760907  frames\\frame_0026.jpg\n","26   87.985855  67.887504  59.760056  frames\\frame_0027.jpg\n","27   88.648290  68.291619  60.394323  frames\\frame_0028.jpg\n","28   88.199457  67.881858  59.730273  frames\\frame_0029.jpg\n","\n","== Notebook Frames ==\n","             r           g           b                  frame\n","29  237.225595  236.513451  236.777122  frames\\frame_0030.jpg\n","30  237.253437  236.602648  236.892174  frames\\frame_0031.jpg\n","31  237.195208  236.540660  236.820846  frames\\frame_0032.jpg\n","32  237.115829  236.491884  236.751220  frames\\frame_0033.jpg\n","33  237.047144  236.413112  236.723785  frames\\frame_0034.jpg\n","34  236.984983  236.333863  236.670365  frames\\frame_0035.jpg\n","35  236.922756  236.294588  236.619852  frames\\frame_0036.jpg\n","36  236.866237  236.240204  236.563247  frames\\frame_0037.jpg\n","37  236.807886  236.201602  236.472214  frames\\frame_0038.jpg\n","38  234.163260  233.208290  233.665586  frames\\frame_0039.jpg\n","39  232.595677  232.036198  232.209505  frames\\frame_0040.jpg\n","40  233.124054  232.524905  232.712209  frames\\frame_0041.jpg\n","41  233.162930  232.555686  232.756845  frames\\frame_0042.jpg\n","42  233.114714  232.519796  232.737435  frames\\frame_0043.jpg\n","43  233.172648  232.531111  232.777283  frames\\frame_0044.jpg\n","44  233.249470  232.604392  232.842834  frames\\frame_0045.jpg\n","45  233.246563  232.578090  232.828377  frames\\frame_0046.jpg\n","46  233.246910  232.578442  232.828724  frames\\frame_0047.jpg\n","47  233.172292  232.569588  232.815490  frames\\frame_0048.jpg\n","48  233.174779  232.570156  232.816693  frames\\frame_0049.jpg\n","49  233.166654  232.568346  232.814792  frames\\frame_0050.jpg\n","50  233.166128  232.567852  232.814297  frames\\frame_0051.jpg\n","51  233.123247  232.546962  232.750234  frames\\frame_0052.jpg\n","52  233.122422  232.548099  232.750773  frames\\frame_0053.jpg\n","53  233.171567  232.579991  232.816007  frames\\frame_0054.jpg\n"]}],"source":["import os\n","\n","print(\"== Office Hour Frames ==\")\n","print( df[ df[\"frame\"].isin( [os.path.join(\"frames\", f\"frame_{frame:04d}.jpg\") for frame in office_hour_frames]) ] )\n","print()\n","print(\"== Notebook Frames ==\")\n","print( df[ df[\"frame\"].isin( [os.path.join(\"frames\", f\"frame_{frame:04d}.jpg\") for frame in notebook_frames]) ] )"]},{"cell_type":"markdown","metadata":{},"source":["### Create Your Classifier Function\n","\n","A **classifier function** is a function that takes data and gives a classification for that data.  Create a new function, `classifyFrame` that receives an `r`, `g`, and `b` value.\n","\n","Using information from your frames above, have the function return the string `\"office hour\"` or `\"notebook\"` based on the values of `r`, `g`, and `b`.\n","\n","**IMPORTANT**: Make sure your classifier can handle **ANY** input -- even frames you have not seen before!  For example, you might decide that you will call a frame an `\"office hour\"` frame if the sum of `r`, `g` and `b` is greater than 100 and otherwise it's a `\"notebook\"` scene."]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["212.20206830929484\n","702.7416083333333\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\bboy2\\AppData\\Local\\Temp\\ipykernel_12040\\1145519915.py:3: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  office[\"sum\"] = office[\"r\"] + office[\"g\"] + office[\"b\"]\n","C:\\Users\\bboy2\\AppData\\Local\\Temp\\ipykernel_12040\\1145519915.py:4: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  notebook[\"sum\"] = notebook[\"r\"] + notebook[\"g\"] + notebook[\"b\"]\n"]}],"source":["office = df[ df[\"frame\"].isin( [os.path.join(\"frames\", f\"frame_{frame:04d}.jpg\") for frame in office_hour_frames]) ]\n","notebook = df[ df[\"frame\"].isin( [os.path.join(\"frames\", f\"frame_{frame:04d}.jpg\") for frame in notebook_frames]) ]\n","office[\"sum\"] = office[\"r\"] + office[\"g\"] + office[\"b\"]\n","notebook[\"sum\"] = notebook[\"r\"] + notebook[\"g\"] + notebook[\"b\"]\n","print(office[\"sum\"].mean())\n","print(notebook[\"sum\"].mean())"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["def classifyFrame(r, g, b):\n","  # Return either \"office hour\" or \"notebook\" based on the values of `r`, `g`, and `b`.\n","  if (r + g + b) > 650:\n","    return \"notebook\"\n","  else:\n","    return \"office hour\""]},{"cell_type":"markdown","metadata":{},"source":["### ðŸ”¬ Checkpoint Tests ðŸ”¬"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["ðŸŽ‰ All Tests Passed! ðŸŽ‰\n"]}],"source":["## == CHECKPOINT TESTS ==\n","# - This read-only cell contains a \"checkpoint\" for this section of the MicroProejct and verifies you are on the right track.\n","# - If this cell results in a celebration message, you PASSED all test cases!\n","# - If this cell results in any errors, check you previous cells, make changes, and RE-RUN your code and then this cell.\n","tada = \"\\N{PARTY POPPER}\"\n","\n","r = classifyFrame(0, 0, 0)\n","assert(r == \"notebook\" or r == \"office hour\")\n","\n","r = classifyFrame(255, 255, 255)\n","assert(r == \"notebook\" or r == \"office hour\")\n","\n","r = classifyFrame(0, 255, 255)\n","assert(r == \"notebook\" or r == \"office hour\")\n","\n","r = classifyFrame(255, 255, 0)\n","assert(r == \"notebook\" or r == \"office hour\")\n","\n","print(f\"{tada} All Tests Passed! {tada}\")"]},{"cell_type":"markdown","metadata":{},"source":["<hr style=\"color: #DD3403;\">"]},{"cell_type":"markdown","metadata":{},"source":["## Part 3: Using Your Classifier!\n","\n","Now that we have a classifier, we should run it on every frame!\n","\n","The following cell runs your `classifyFrame` classifier on every frame and adds a new column `scene` and displayed 20 random rows:"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>r</th>\n","      <th>g</th>\n","      <th>b</th>\n","      <th>frame</th>\n","      <th>scene</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>210</th>\n","      <td>238.529397</td>\n","      <td>237.846072</td>\n","      <td>235.496111</td>\n","      <td>frames\\frame_0211.jpg</td>\n","      <td>notebook</td>\n","    </tr>\n","    <tr>\n","      <th>174</th>\n","      <td>90.188828</td>\n","      <td>71.015408</td>\n","      <td>63.906680</td>\n","      <td>frames\\frame_0175.jpg</td>\n","      <td>office hour</td>\n","    </tr>\n","    <tr>\n","      <th>211</th>\n","      <td>238.534297</td>\n","      <td>237.856402</td>\n","      <td>235.515777</td>\n","      <td>frames\\frame_0212.jpg</td>\n","      <td>notebook</td>\n","    </tr>\n","    <tr>\n","      <th>221</th>\n","      <td>244.537031</td>\n","      <td>243.870859</td>\n","      <td>242.090972</td>\n","      <td>frames\\frame_0222.jpg</td>\n","      <td>notebook</td>\n","    </tr>\n","    <tr>\n","      <th>93</th>\n","      <td>230.418442</td>\n","      <td>230.041072</td>\n","      <td>230.527708</td>\n","      <td>frames\\frame_0094.jpg</td>\n","      <td>notebook</td>\n","    </tr>\n","    <tr>\n","      <th>196</th>\n","      <td>238.847509</td>\n","      <td>238.228464</td>\n","      <td>235.758216</td>\n","      <td>frames\\frame_0197.jpg</td>\n","      <td>notebook</td>\n","    </tr>\n","    <tr>\n","      <th>116</th>\n","      <td>87.449635</td>\n","      <td>67.878451</td>\n","      <td>60.402622</td>\n","      <td>frames\\frame_0117.jpg</td>\n","      <td>office hour</td>\n","    </tr>\n","    <tr>\n","      <th>295</th>\n","      <td>89.262960</td>\n","      <td>70.056289</td>\n","      <td>62.709128</td>\n","      <td>frames\\frame_0296.jpg</td>\n","      <td>office hour</td>\n","    </tr>\n","    <tr>\n","      <th>328</th>\n","      <td>7.480004</td>\n","      <td>7.481289</td>\n","      <td>7.487595</td>\n","      <td>frames\\frame_0329.jpg</td>\n","      <td>office hour</td>\n","    </tr>\n","    <tr>\n","      <th>241</th>\n","      <td>244.172700</td>\n","      <td>243.404648</td>\n","      <td>241.769227</td>\n","      <td>frames\\frame_0242.jpg</td>\n","      <td>notebook</td>\n","    </tr>\n","    <tr>\n","      <th>78</th>\n","      <td>230.676610</td>\n","      <td>229.869766</td>\n","      <td>230.503785</td>\n","      <td>frames\\frame_0079.jpg</td>\n","      <td>notebook</td>\n","    </tr>\n","    <tr>\n","      <th>288</th>\n","      <td>241.932990</td>\n","      <td>240.723173</td>\n","      <td>239.471111</td>\n","      <td>frames\\frame_0289.jpg</td>\n","      <td>notebook</td>\n","    </tr>\n","    <tr>\n","      <th>329</th>\n","      <td>4.657478</td>\n","      <td>4.658776</td>\n","      <td>4.665082</td>\n","      <td>frames\\frame_0330.jpg</td>\n","      <td>office hour</td>\n","    </tr>\n","    <tr>\n","      <th>47</th>\n","      <td>233.172292</td>\n","      <td>232.569588</td>\n","      <td>232.815490</td>\n","      <td>frames\\frame_0048.jpg</td>\n","      <td>notebook</td>\n","    </tr>\n","    <tr>\n","      <th>263</th>\n","      <td>243.804492</td>\n","      <td>242.946359</td>\n","      <td>241.374149</td>\n","      <td>frames\\frame_0264.jpg</td>\n","      <td>notebook</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>87.667374</td>\n","      <td>66.617891</td>\n","      <td>59.294557</td>\n","      <td>frames\\frame_0021.jpg</td>\n","      <td>office hour</td>\n","    </tr>\n","    <tr>\n","      <th>234</th>\n","      <td>244.675399</td>\n","      <td>244.029071</td>\n","      <td>242.162010</td>\n","      <td>frames\\frame_0235.jpg</td>\n","      <td>notebook</td>\n","    </tr>\n","    <tr>\n","      <th>310</th>\n","      <td>89.052721</td>\n","      <td>70.084679</td>\n","      <td>62.528559</td>\n","      <td>frames\\frame_0311.jpg</td>\n","      <td>office hour</td>\n","    </tr>\n","    <tr>\n","      <th>205</th>\n","      <td>238.592674</td>\n","      <td>237.855048</td>\n","      <td>235.574865</td>\n","      <td>frames\\frame_0206.jpg</td>\n","      <td>notebook</td>\n","    </tr>\n","    <tr>\n","      <th>64</th>\n","      <td>231.244536</td>\n","      <td>230.689201</td>\n","      <td>230.925812</td>\n","      <td>frames\\frame_0065.jpg</td>\n","      <td>notebook</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["              r           g           b                  frame        scene\n","210  238.529397  237.846072  235.496111  frames\\frame_0211.jpg     notebook\n","174   90.188828   71.015408   63.906680  frames\\frame_0175.jpg  office hour\n","211  238.534297  237.856402  235.515777  frames\\frame_0212.jpg     notebook\n","221  244.537031  243.870859  242.090972  frames\\frame_0222.jpg     notebook\n","93   230.418442  230.041072  230.527708  frames\\frame_0094.jpg     notebook\n","196  238.847509  238.228464  235.758216  frames\\frame_0197.jpg     notebook\n","116   87.449635   67.878451   60.402622  frames\\frame_0117.jpg  office hour\n","295   89.262960   70.056289   62.709128  frames\\frame_0296.jpg  office hour\n","328    7.480004    7.481289    7.487595  frames\\frame_0329.jpg  office hour\n","241  244.172700  243.404648  241.769227  frames\\frame_0242.jpg     notebook\n","78   230.676610  229.869766  230.503785  frames\\frame_0079.jpg     notebook\n","288  241.932990  240.723173  239.471111  frames\\frame_0289.jpg     notebook\n","329    4.657478    4.658776    4.665082  frames\\frame_0330.jpg  office hour\n","47   233.172292  232.569588  232.815490  frames\\frame_0048.jpg     notebook\n","263  243.804492  242.946359  241.374149  frames\\frame_0264.jpg     notebook\n","20    87.667374   66.617891   59.294557  frames\\frame_0021.jpg  office hour\n","234  244.675399  244.029071  242.162010  frames\\frame_0235.jpg     notebook\n","310   89.052721   70.084679   62.528559  frames\\frame_0311.jpg  office hour\n","205  238.592674  237.855048  235.574865  frames\\frame_0206.jpg     notebook\n","64   231.244536  230.689201  230.925812  frames\\frame_0065.jpg     notebook"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["df[\"scene\"] = df.apply(lambda row: classifyFrame(row.r, row.g, row.b), axis=1)\n","df.sample(20)"]},{"cell_type":"markdown","metadata":{},"source":["### ðŸ”¬ Checkpoint Tests ðŸ”¬"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["ðŸŽ‰ All Tests Passed! ðŸŽ‰\n"]}],"source":["## == CHECKPOINT TESTS ==\n","# - This read-only cell contains a \"checkpoint\" for this section of the MicroProejct and verifies you are on the right track.\n","# - If this cell results in a celebration message, you PASSED all test cases!\n","# - If this cell results in any errors, check you previous cells, make changes, and RE-RUN your code and then this cell.\n","tada = \"\\N{PARTY POPPER}\"\n","\n","assert(\"scene\" in df)\n","\n","assert(len(df[ df.scene == \"notebook\" ]) > 100), \"There are more than 100 frames that are clearly the notebook.  Make sure your classifier is able to pick up the notebook scene accurately.\"\n","assert(len(df[ df.scene == \"office hour\" ]) > 75), \"There are more than 75 frames that are clearly the office hour set.  Make sure your classifier is able to pick up the office hour set scene accurately.\"\n","assert(len(df[ df.scene == \"notebook\" ]) + len(df[ df.scene == \"office hour\" ]) == len(df)), \"Your classifier should must always identify a scene as either a notebook or office hour.  Make sure your classifier always returns one of those two values.\"\n","\n","assert( len( df[ (df.frame.str.endswith(\"0001.jpg\")) & (df.scene == \"office hour\") ] ) == 1 )\n","assert( len( df[ (df.frame.str.endswith(\"0306.jpg\")) & (df.scene == \"office hour\") ] ) == 1 )\n","assert( len( df[ (df.frame.str.endswith(\"0081.jpg\")) & (df.scene == \"notebook\") ] ) == 1 )\n","assert( len( df[ (df.frame.str.endswith(\"0191.jpg\")) & (df.scene == \"notebook\") ] ) == 1 )\n","\n","print(f\"{tada} All Tests Passed! {tada}\")"]},{"cell_type":"markdown","metadata":{},"source":["## Observing Results\n","\n","In the next 5 cells, we display a frame and you'll run code to check what your classifier classified the frame as being!  Make sure to run the code for each frame:"]},{"cell_type":"markdown","metadata":{},"source":["### Frame #0001: Office Hours"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>r</th>\n","      <th>g</th>\n","      <th>b</th>\n","      <th>frame</th>\n","      <th>scene</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>88.659175</td>\n","      <td>67.456202</td>\n","      <td>60.424978</td>\n","      <td>frames\\frame_0001.jpg</td>\n","      <td>office hour</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["           r          g          b                  frame        scene\n","0  88.659175  67.456202  60.424978  frames\\frame_0001.jpg  office hour"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["df[ df.frame.str.endswith(\"0001.jpg\") ]"]},{"cell_type":"markdown","metadata":{},"source":["![Frame 0001](frames/frame_0001.jpg)"]},{"cell_type":"markdown","metadata":{},"source":["### Frame #0081: Notebook"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>r</th>\n","      <th>g</th>\n","      <th>b</th>\n","      <th>frame</th>\n","      <th>scene</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>80</th>\n","      <td>230.721385</td>\n","      <td>229.915091</td>\n","      <td>230.48303</td>\n","      <td>frames\\frame_0081.jpg</td>\n","      <td>notebook</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["             r           g          b                  frame     scene\n","80  230.721385  229.915091  230.48303  frames\\frame_0081.jpg  notebook"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["df[ df.frame.str.endswith(\"0081.jpg\") ]"]},{"cell_type":"markdown","metadata":{},"source":["![Frame 0001](frames/frame_0081.jpg)"]},{"cell_type":"markdown","metadata":{},"source":["### Frame #0191: Notebook"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>r</th>\n","      <th>g</th>\n","      <th>b</th>\n","      <th>frame</th>\n","      <th>scene</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>190</th>\n","      <td>233.117088</td>\n","      <td>232.354644</td>\n","      <td>230.103359</td>\n","      <td>frames\\frame_0191.jpg</td>\n","      <td>notebook</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["              r           g           b                  frame     scene\n","190  233.117088  232.354644  230.103359  frames\\frame_0191.jpg  notebook"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["df[ df.frame.str.endswith(\"0191.jpg\") ]"]},{"cell_type":"markdown","metadata":{},"source":["![Frame 0001](frames/frame_0191.jpg)"]},{"cell_type":"markdown","metadata":{},"source":["### Frame #0306: Office Hours"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>r</th>\n","      <th>g</th>\n","      <th>b</th>\n","      <th>frame</th>\n","      <th>scene</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>305</th>\n","      <td>89.403867</td>\n","      <td>70.149223</td>\n","      <td>62.83901</td>\n","      <td>frames\\frame_0306.jpg</td>\n","      <td>office hour</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["             r          g         b                  frame        scene\n","305  89.403867  70.149223  62.83901  frames\\frame_0306.jpg  office hour"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["df[ df.frame.str.endswith(\"0306.jpg\") ]"]},{"cell_type":"markdown","metadata":{},"source":["![Frame 0001](frames/frame_0306.jpg)"]},{"cell_type":"markdown","metadata":{},"source":["### Frame #0320: Data Science Duo Logo???\n","\n","What did you classify the DUO logo as?  It's nether one, but we don't have that option!"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>r</th>\n","      <th>g</th>\n","      <th>b</th>\n","      <th>frame</th>\n","      <th>scene</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>319</th>\n","      <td>221.227565</td>\n","      <td>71.838433</td>\n","      <td>54.457305</td>\n","      <td>frames\\frame_0320.jpg</td>\n","      <td>office hour</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["              r          g          b                  frame        scene\n","319  221.227565  71.838433  54.457305  frames\\frame_0320.jpg  office hour"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["df[ df.frame.str.endswith(\"0320.jpg\") ]"]},{"cell_type":"markdown","metadata":{},"source":["![Frame 0001](frames/frame_0320.jpg)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Frame #328: Video Credits\n","\n","What did you classify the video credits as?  It's another tricky one!\n"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>r</th>\n","      <th>g</th>\n","      <th>b</th>\n","      <th>frame</th>\n","      <th>scene</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>327</th>\n","      <td>7.480234</td>\n","      <td>7.481519</td>\n","      <td>7.487826</td>\n","      <td>frames\\frame_0328.jpg</td>\n","      <td>office hour</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["            r         g         b                  frame        scene\n","327  7.480234  7.481519  7.487826  frames\\frame_0328.jpg  office hour"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["df[ df.frame.str.endswith(\"0328.jpg\") ]"]},{"cell_type":"markdown","metadata":{},"source":["![Frame 0328](frames/frame_0328.jpg)"]},{"cell_type":"markdown","metadata":{},"source":["<hr style=\"color: #DD3403;\">"]},{"cell_type":"markdown","metadata":{},"source":["## Part 4: Update Your Classifier to Account with an \"Other\" Category\n","\n","Create a second classifier -- `classifyFrame2` -- that returns either `\"notebook\"`, `\"office hour\"` or `\"other\"`.  Your classifier should correctly handle the \"Data Science Duo\" (ex: #0320) frames and the \"Credit\" frames (ex: #0328)."]},{"cell_type":"code","execution_count":36,"metadata":{},"outputs":[],"source":["other_frames1 = [6, 7, 8, 316, 317, 318, 319, 320, 321, 322, 323, 324]\n","other_frames2 = [325, 326, 327, 328, 329, 330]"]},{"cell_type":"code","execution_count":37,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["307.89408130787035\n","17.30290581597222\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\bboy2\\AppData\\Local\\Temp\\ipykernel_12040\\2707644543.py:3: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  other_frames3[\"sum\"] = other_frames3[\"r\"] + other_frames3[\"g\"] + other_frames3[\"b\"]\n","C:\\Users\\bboy2\\AppData\\Local\\Temp\\ipykernel_12040\\2707644543.py:4: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  other_frames4[\"sum\"] = other_frames4[\"r\"] + other_frames4[\"g\"] + other_frames4[\"b\"]\n"]}],"source":["other_frames3 = df[ df[\"frame\"].isin( [os.path.join(\"frames\", f\"frame_{frame:04d}.jpg\") for frame in other_frames1])  ]\n","other_frames4 = df[ df[\"frame\"].isin( [os.path.join(\"frames\", f\"frame_{frame:04d}.jpg\") for frame in other_frames2])  ]\n","other_frames3[\"sum\"] = other_frames3[\"r\"] + other_frames3[\"g\"] + other_frames3[\"b\"]\n","other_frames4[\"sum\"] = other_frames4[\"r\"] + other_frames4[\"g\"] + other_frames4[\"b\"]\n","print(other_frames3[\"sum\"].mean())\n","print(other_frames4[\"sum\"].mean())"]},{"cell_type":"code","execution_count":40,"metadata":{},"outputs":[],"source":["def classifyFrame2(r, g, b):\n","  # Return either \"office hour\", \"notebook\", or \"other\" based on the values of `r`, `g`, and `b`.\n","  oh_avg = 212.20206830929484\n","  n_avg = 702.7416083333333\n","  o1_avg = 307.89408130787035\n","  o2_avg = 17.30290581597222\n","  sum_input = r + g + b\n","  distance_officehour = ( (oh_avg - sum_input)**2 )**0.5\n","  distance_notebook = ( (n_avg - sum_input)**2 )**0.5\n","  distance_other1 = ( (o1_avg - sum_input)**2 )**0.5\n","  distance_other2 = ( (o2_avg - sum_input)**2 )**0.5\n","  if distance_officehour < distance_notebook:\n","    if distance_officehour < distance_other1:\n","      if distance_officehour < distance_other2:\n","        return \"office hour\"\n","      else:\n","        return \"other\"\n","    else:\n","      return \"other\"\n","  else:\n","    return \"notebook\"\n","  "]},{"cell_type":"markdown","metadata":{},"source":["## Apply your `classifyFrame2` function\n","\n","Using `classifyFrame2`, this code replaces the value in the column `scene` with your `classifyFrame2` classification function.  The output of this cell shows the last frames of the video, which we expect to be `\"other\"`:"]},{"cell_type":"code","execution_count":41,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>r</th>\n","      <th>g</th>\n","      <th>b</th>\n","      <th>frame</th>\n","      <th>scene</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>310</th>\n","      <td>89.052721</td>\n","      <td>70.084679</td>\n","      <td>62.528559</td>\n","      <td>frames\\frame_0311.jpg</td>\n","      <td>office hour</td>\n","    </tr>\n","    <tr>\n","      <th>311</th>\n","      <td>89.577539</td>\n","      <td>70.261745</td>\n","      <td>62.894870</td>\n","      <td>frames\\frame_0312.jpg</td>\n","      <td>office hour</td>\n","    </tr>\n","    <tr>\n","      <th>312</th>\n","      <td>89.365169</td>\n","      <td>70.192526</td>\n","      <td>62.526467</td>\n","      <td>frames\\frame_0313.jpg</td>\n","      <td>office hour</td>\n","    </tr>\n","    <tr>\n","      <th>313</th>\n","      <td>89.240360</td>\n","      <td>70.183095</td>\n","      <td>62.777127</td>\n","      <td>frames\\frame_0314.jpg</td>\n","      <td>office hour</td>\n","    </tr>\n","    <tr>\n","      <th>314</th>\n","      <td>89.053277</td>\n","      <td>70.115230</td>\n","      <td>62.639093</td>\n","      <td>frames\\frame_0315.jpg</td>\n","      <td>office hour</td>\n","    </tr>\n","    <tr>\n","      <th>315</th>\n","      <td>227.706259</td>\n","      <td>67.024722</td>\n","      <td>48.608728</td>\n","      <td>frames\\frame_0316.jpg</td>\n","      <td>other</td>\n","    </tr>\n","    <tr>\n","      <th>316</th>\n","      <td>233.539870</td>\n","      <td>66.995486</td>\n","      <td>47.766740</td>\n","      <td>frames\\frame_0317.jpg</td>\n","      <td>other</td>\n","    </tr>\n","    <tr>\n","      <th>317</th>\n","      <td>227.335317</td>\n","      <td>67.101398</td>\n","      <td>48.556484</td>\n","      <td>frames\\frame_0318.jpg</td>\n","      <td>other</td>\n","    </tr>\n","    <tr>\n","      <th>318</th>\n","      <td>221.847739</td>\n","      <td>72.007214</td>\n","      <td>54.584670</td>\n","      <td>frames\\frame_0319.jpg</td>\n","      <td>other</td>\n","    </tr>\n","    <tr>\n","      <th>319</th>\n","      <td>221.227565</td>\n","      <td>71.838433</td>\n","      <td>54.457305</td>\n","      <td>frames\\frame_0320.jpg</td>\n","      <td>other</td>\n","    </tr>\n","    <tr>\n","      <th>320</th>\n","      <td>218.887899</td>\n","      <td>80.898411</td>\n","      <td>63.118472</td>\n","      <td>frames\\frame_0321.jpg</td>\n","      <td>other</td>\n","    </tr>\n","    <tr>\n","      <th>321</th>\n","      <td>200.769965</td>\n","      <td>41.149089</td>\n","      <td>18.975074</td>\n","      <td>frames\\frame_0322.jpg</td>\n","      <td>other</td>\n","    </tr>\n","    <tr>\n","      <th>322</th>\n","      <td>201.348303</td>\n","      <td>42.190686</td>\n","      <td>19.636580</td>\n","      <td>frames\\frame_0323.jpg</td>\n","      <td>other</td>\n","    </tr>\n","    <tr>\n","      <th>323</th>\n","      <td>201.755673</td>\n","      <td>42.935651</td>\n","      <td>20.674631</td>\n","      <td>frames\\frame_0324.jpg</td>\n","      <td>other</td>\n","    </tr>\n","    <tr>\n","      <th>324</th>\n","      <td>0.025247</td>\n","      <td>0.030256</td>\n","      <td>0.038095</td>\n","      <td>frames\\frame_0325.jpg</td>\n","      <td>other</td>\n","    </tr>\n","    <tr>\n","      <th>325</th>\n","      <td>7.470391</td>\n","      <td>7.473355</td>\n","      <td>7.479188</td>\n","      <td>frames\\frame_0326.jpg</td>\n","      <td>other</td>\n","    </tr>\n","    <tr>\n","      <th>326</th>\n","      <td>7.469779</td>\n","      <td>7.472743</td>\n","      <td>7.478576</td>\n","      <td>frames\\frame_0327.jpg</td>\n","      <td>other</td>\n","    </tr>\n","    <tr>\n","      <th>327</th>\n","      <td>7.480234</td>\n","      <td>7.481519</td>\n","      <td>7.487826</td>\n","      <td>frames\\frame_0328.jpg</td>\n","      <td>other</td>\n","    </tr>\n","    <tr>\n","      <th>328</th>\n","      <td>7.480004</td>\n","      <td>7.481289</td>\n","      <td>7.487595</td>\n","      <td>frames\\frame_0329.jpg</td>\n","      <td>other</td>\n","    </tr>\n","    <tr>\n","      <th>329</th>\n","      <td>4.657478</td>\n","      <td>4.658776</td>\n","      <td>4.665082</td>\n","      <td>frames\\frame_0330.jpg</td>\n","      <td>other</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["              r          g          b                  frame        scene\n","310   89.052721  70.084679  62.528559  frames\\frame_0311.jpg  office hour\n","311   89.577539  70.261745  62.894870  frames\\frame_0312.jpg  office hour\n","312   89.365169  70.192526  62.526467  frames\\frame_0313.jpg  office hour\n","313   89.240360  70.183095  62.777127  frames\\frame_0314.jpg  office hour\n","314   89.053277  70.115230  62.639093  frames\\frame_0315.jpg  office hour\n","315  227.706259  67.024722  48.608728  frames\\frame_0316.jpg        other\n","316  233.539870  66.995486  47.766740  frames\\frame_0317.jpg        other\n","317  227.335317  67.101398  48.556484  frames\\frame_0318.jpg        other\n","318  221.847739  72.007214  54.584670  frames\\frame_0319.jpg        other\n","319  221.227565  71.838433  54.457305  frames\\frame_0320.jpg        other\n","320  218.887899  80.898411  63.118472  frames\\frame_0321.jpg        other\n","321  200.769965  41.149089  18.975074  frames\\frame_0322.jpg        other\n","322  201.348303  42.190686  19.636580  frames\\frame_0323.jpg        other\n","323  201.755673  42.935651  20.674631  frames\\frame_0324.jpg        other\n","324    0.025247   0.030256   0.038095  frames\\frame_0325.jpg        other\n","325    7.470391   7.473355   7.479188  frames\\frame_0326.jpg        other\n","326    7.469779   7.472743   7.478576  frames\\frame_0327.jpg        other\n","327    7.480234   7.481519   7.487826  frames\\frame_0328.jpg        other\n","328    7.480004   7.481289   7.487595  frames\\frame_0329.jpg        other\n","329    4.657478   4.658776   4.665082  frames\\frame_0330.jpg        other"]},"execution_count":41,"metadata":{},"output_type":"execute_result"}],"source":["df[\"scene\"] = df.apply(lambda row: classifyFrame2(row.r, row.g, row.b), axis=1)\n","df.tail(20)"]},{"cell_type":"markdown","metadata":{},"source":["### ðŸ”¬ Checkpoint Tests ðŸ”¬"]},{"cell_type":"code","execution_count":42,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["ðŸŽ‰ All Tests Passed! ðŸŽ‰\n"]}],"source":["## == CHECKPOINT TESTS ==\n","# - This read-only cell contains a \"checkpoint\" for this section of the MicroProejct and verifies you are on the right track.\n","# - If this cell results in a celebration message, you PASSED all test cases!\n","# - If this cell results in any errors, check you previous cells, make changes, and RE-RUN your code and then this cell.\n","tada = \"\\N{PARTY POPPER}\"\n","\n","assert(\"scene\" in df)\n","\n","assert(len(df[ df.scene == \"notebook\" ]) > 100)\n","assert(len(df[ df.scene == \"office hour\" ]) > 75)\n","assert(len(df[ df.scene == \"other\" ]) >= 15)\n","assert(len(df[ df.scene == \"other\" ]) <= 18)   # It's okay to classify the intro screens as \"other\" as well -- but not any others.\n","assert(len(df[ df.scene == \"notebook\" ]) + len(df[ df.scene == \"office hour\" ]) + len(df[ df.scene == \"other\" ]) == len(df))\n","\n","assert( len( df[ (df.frame.str.endswith(\"0001.jpg\")) & (df.scene == \"office hour\") ] ) == 1 )\n","assert( len( df[ (df.frame.str.endswith(\"0306.jpg\")) & (df.scene == \"office hour\") ] ) == 1 )\n","assert( len( df[ (df.frame.str.endswith(\"0081.jpg\")) & (df.scene == \"notebook\") ] ) == 1 )\n","assert( len( df[ (df.frame.str.endswith(\"0191.jpg\")) & (df.scene == \"notebook\") ] ) == 1 )\n","assert( len( df[ (df.frame.str.endswith(\"0317.jpg\")) & (df.scene == \"other\") ] ) == 1 )\n","assert( len( df[ (df.frame.str.endswith(\"0325.jpg\")) & (df.scene == \"other\") ] ) == 1 )\n","assert( len( df[ (df.frame.str.endswith(\"0328.jpg\")) & (df.scene == \"other\") ] ) == 1 )\n","\n","print(f\"{tada} All Tests Passed! {tada}\")"]},{"cell_type":"markdown","metadata":{},"source":["<hr style=\"color: #DD3403;\">"]},{"cell_type":"markdown","metadata":{},"source":["## Submission\n","\n","You're almost done!  All you need to do is to commit your lab to GitHub and run the GitHub Actions Grader:\n","\n","1.  âš ï¸ **Make certain to save your work.** âš ï¸ To do this, go to **File => Save All**\n","\n","2.  After you have saved, exit this notebook and follow the instructions to commit and grade this MicroProject!"]}],"metadata":{"kernelspec":{"display_name":"Python 3.10.5 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.11"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"}}},"nbformat":4,"nbformat_minor":2}
